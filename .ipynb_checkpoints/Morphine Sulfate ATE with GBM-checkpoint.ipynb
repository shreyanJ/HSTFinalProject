{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Description</h3>\n",
    "<p>\n",
    "    The `admissions_processed_morphine_sulfate.csv` file is processed as follows, and is a combination of the `PRESCRIPTIONS.csv`, `ADMISSIONS.csv` and `PATIENTS.csv` files found from the MIMIC-III database,\n",
    "    <ul>\n",
    "        <li> There are `6618` unique patients. Each patient could have had multiple hospital stays, but we only considered the first hospital stay that the patient had. The rationale is that we wanted a first impression of the patient.\n",
    "        <li> These 6618 patients comprise four ethnicities: [WHITE, BLACK, ASIAN, HISPANIC] </li>\n",
    "        <li> The diagnosis that were selected for consideration were only those that were shared by all four ethnic groups, there is a distribution of these diagnostics among each group in the other jupyter notebook. </li>\n",
    "        <li> Ages were calculated by taking the difference between birthdate and admittime, for ages that were negative due to HIPAA compliance, we readjusted them to all be 89. </li>\n",
    "        <li> 122 covariates are considered: [age, HOSPITAL_EXPIRE_FLAG, DIAGNOSIS:%s (114 of them), hosp_duration, INSURANCE (5 types)] </li>\n",
    "        <li> Only patients that were administered morphine sulfate were then considered, we looked at the total amount they were administered for their single hospital stay duration by taking the FORM_VAL_RX value of the drug.\n",
    "    </ul>\n",
    "</p>\n",
    "<p> Covariates are described above, there are 122 of them, e.g. age and different diagnosis types </p>\n",
    "<p>Treatment is done by comparing one ethnic group vs the rest, e.g. (WHITE vs [ASIAN, BLACK, HISPANIC]) or (BLACK vs [ASIAN, WHITE, HISPANIC) </p>\n",
    "<p>Output is the amount of the morphine sulfate the patient is administered</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/admissions_processed_morphine_sulfate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>ADMISSION_LOCATION</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>MARITAL_STATUS</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>EDREGTIME</th>\n",
       "      <th>EDOUTTIME</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
       "      <th>HAS_CHARTEVENTS_DATA</th>\n",
       "      <th>age</th>\n",
       "      <th>TOTAL_FORM_VAL_DISP_MAX</th>\n",
       "      <th>drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>194540</td>\n",
       "      <td>2178-04-16 06:18:00</td>\n",
       "      <td>2178-05-11 19:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2178-04-15 20:46:00</td>\n",
       "      <td>2178-04-16 06:53:00</td>\n",
       "      <td>brain mass</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>Morphine Sulfate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>143045</td>\n",
       "      <td>2167-01-08 18:43:00</td>\n",
       "      <td>2167-01-15 15:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coronary artery disease</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Morphine Sulfate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>157681</td>\n",
       "      <td>2183-04-28 09:45:00</td>\n",
       "      <td>2183-05-03 14:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coronary artery disease\\coronary artery bypass...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Morphine Sulfate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>109451</td>\n",
       "      <td>2134-09-11 12:17:00</td>\n",
       "      <td>2134-09-24 16:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>REHAB/DISTINCT PART HOSP</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2134-09-11 09:22:00</td>\n",
       "      <td>2134-09-11 22:30:00</td>\n",
       "      <td>congestive heart failure</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Morphine Sulfate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>152223</td>\n",
       "      <td>2153-09-03 07:15:00</td>\n",
       "      <td>2153-09-08 19:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coronary artery disease\\coronary artery bypass...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0.40</td>\n",
       "      <td>Morphine Sulfate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID  HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "0      10          11   194540  2178-04-16 06:18:00  2178-05-11 19:00:00   \n",
       "1      12          13   143045  2167-01-08 18:43:00  2167-01-15 15:15:00   \n",
       "2      18          20   157681  2183-04-28 09:45:00  2183-05-03 14:45:00   \n",
       "3      19          21   109451  2134-09-11 12:17:00  2134-09-24 16:15:00   \n",
       "4      22          23   152223  2153-09-03 07:15:00  2153-09-08 19:10:00   \n",
       "\n",
       "  DEATHTIME ADMISSION_TYPE         ADMISSION_LOCATION  \\\n",
       "0       NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "1       NaN      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "2       NaN       ELECTIVE  PHYS REFERRAL/NORMAL DELI   \n",
       "3       NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "4       NaN       ELECTIVE  PHYS REFERRAL/NORMAL DELI   \n",
       "\n",
       "         DISCHARGE_LOCATION INSURANCE        ...        MARITAL_STATUS  \\\n",
       "0          HOME HEALTH CARE   Private        ...               MARRIED   \n",
       "1          HOME HEALTH CARE  Medicaid        ...                   NaN   \n",
       "2                      HOME  Medicare        ...               WIDOWED   \n",
       "3  REHAB/DISTINCT PART HOSP  Medicare        ...               MARRIED   \n",
       "4          HOME HEALTH CARE  Medicare        ...               MARRIED   \n",
       "\n",
       "  ETHNICITY            EDREGTIME            EDOUTTIME  \\\n",
       "0     WHITE  2178-04-15 20:46:00  2178-04-16 06:53:00   \n",
       "1     WHITE                  NaN                  NaN   \n",
       "2     WHITE                  NaN                  NaN   \n",
       "3     WHITE  2134-09-11 09:22:00  2134-09-11 22:30:00   \n",
       "4     WHITE                  NaN                  NaN   \n",
       "\n",
       "                                           DIAGNOSIS HOSPITAL_EXPIRE_FLAG  \\\n",
       "0                                         brain mass                    0   \n",
       "1                            coronary artery disease                    0   \n",
       "2  coronary artery disease\\coronary artery bypass...                    0   \n",
       "3                           congestive heart failure                    0   \n",
       "4  coronary artery disease\\coronary artery bypass...                    0   \n",
       "\n",
       "  HAS_CHARTEVENTS_DATA  age  TOTAL_FORM_VAL_DISP_MAX              drug  \n",
       "0                    1   50                     1.25  Morphine Sulfate  \n",
       "1                    1   39                     2.00  Morphine Sulfate  \n",
       "2                    1   75                     3.00  Morphine Sulfate  \n",
       "3                    1   87                     2.00  Morphine Sulfate  \n",
       "4                    1   71                     0.40  Morphine Sulfate  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X(df):\n",
    "    \n",
    "    # include age and hospital expire flag\n",
    "    covariates = ['age', 'HOSPITAL_EXPIRE_FLAG']\n",
    "    X = df[covariates]\n",
    "    \n",
    "    # include onehots for diagnosis\n",
    "    diagnosis = pd.get_dummies(df.DIAGNOSIS)\n",
    "    diagnosis.columns = ['DIAGNOSIS:%s' %d for d in diagnosis.columns]\n",
    "    X = pd.concat([X, diagnosis], axis=1)\n",
    "    \n",
    "    # include duration of hosptial stay\n",
    "    hosp_duration = (df['DISCHTIME'].astype('datetime64[ns]') - df['ADMITTIME'].astype('datetime64[ns]')).dt.days\n",
    "    X['hosp_duration'] = hosp_duration\n",
    "    \n",
    "    # include onehots for insurance\n",
    "    insur = pd.get_dummies(df.INSURANCE)\n",
    "    insur.columns = ['INSURANCE:%s' %i for i in insur.columns]\n",
    "    X = pd.concat([X, insur], axis=1)  \n",
    "\n",
    "    \n",
    "    # normalize duration because it is non-categorical\n",
    "    d_mu = X['hosp_duration'].mean()\n",
    "    d_std = X['hosp_duration'].std()\n",
    "    X['hosp_duration'] = X['hosp_duration'].apply(lambda dp: (dp-d_mu)/d_std)\n",
    "\n",
    "    # normalize age because non-categorical\n",
    "    age_mu = X['age'].mean()\n",
    "    age_std = X['age'].std()\n",
    "    X['age'] = X['age'].apply(lambda age: (age-age_mu)/age_std)\n",
    "\n",
    "    return X\n",
    "\n",
    "def df_to_T(df, eth):\n",
    "    return df['ETHNICITY'].apply(lambda x: int(x==eth))\n",
    "\n",
    "def df_to_Y(df):\n",
    "    return df['TOTAL_FORM_VAL_DISP_MAX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (6618, 122)\n",
      "T:  (6618,)\n",
      "Y:  (6618,)\n"
     ]
    }
   ],
   "source": [
    "X = df_to_X(df)\n",
    "T = df_to_T(df, 'WHITE')\n",
    "Y = df_to_Y(df)\n",
    "print('X: ', X.shape)\n",
    "print(\"T: \", T.shape)\n",
    "print(\"Y: \", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing ATE with Check for Balance using GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GradBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ate_for_treatment_pair(t1, t2):\n",
    "    T1 = df_to_T(df, t1)\n",
    "    T2 = df_to_T(df, t2)\n",
    "\n",
    "    clf1 = GradBoost(n_estimators=500).fit(X, T1)\n",
    "    clf2 = GradBoost(n_estimators=500).fit(X, T2)\n",
    "    \n",
    "    # in class, the formula was (sum_{treated} weight * outcome) / n, where n is the size of the dataset\n",
    "    # in the paper, the formula is (sum_{treated} weight * outcome) / (sum_{treated} weight)\n",
    "    # gonna go with class approach here, but note that the other approach might give better results\n",
    "    # edit: checked and class approach gives ATE of 0.6 but other gives just 0.02\n",
    "    treated1 = (T1 == 1)\n",
    "    X1 = X[treated1]\n",
    "    prop_weights1 = (len(X1) / len(X)) * np.reciprocal(clf1.predict_proba(X1)[:,1])\n",
    "    reciprocal1 = len(X1) # np.sum(prop_weights1)\n",
    "    weighted_mean1 = sum(np.multiply(Y[treated1], prop_weights1)) / reciprocal1\n",
    "\n",
    "    treated2 = (T2 == 1)\n",
    "    X2 = X[treated2]\n",
    "    prop_weights2 = (len(X2) / len(X)) * np.reciprocal(clf2.predict_proba(X2)[:,1])\n",
    "    reciprocal2 = len(X2) # np.sum(prop_weights2)\n",
    "    weighted_mean2 = sum(np.multiply(Y[treated2], prop_weights2)) / reciprocal2\n",
    "\n",
    "    print('weighted mean for treatment 1: {}'.format(weighted_mean1))\n",
    "    print('weighted mean for treatment 2: {}'.format(weighted_mean2))\n",
    "    print('ATE: {}'.format(weighted_mean1 - weighted_mean2))\n",
    "    \n",
    "    # compute unweighted mean and standard deviation of each covariate for the pooled sample across all treatments\n",
    "    population_covariate_means = np.array(X.mean(axis=0))\n",
    "    population_covariate_stds = np.array(X.std(axis=0))\n",
    "    \n",
    "    # compare the population that got treatment 1 after weighting to the unweighted full population\n",
    "    covariates1 = np.array(X1)\n",
    "    weights1 = prop_weights1.reshape((len(prop_weights1), 1))\n",
    "    weighted_covariates1 = np.multiply(covariates1, weights1)\n",
    "    covariate_means1 = np.array(weighted_covariates1.mean(axis=0))\n",
    "\n",
    "    PSB1 = np.divide(np.abs(covariate_means1 - population_covariate_means), population_covariate_stds)\n",
    "    bad_covariates1 = []\n",
    "    for i in range(len(PSB1)):\n",
    "        if PSB1[i] > 0.2:\n",
    "            bad_covariates1.append((i, PSB1[i]))\n",
    "    \n",
    "    print(\"Covariates for Group 1 with Standad Bias > 0.2: {}\".format(bad_covariates1))\n",
    "    \n",
    "    covariates2 = np.array(X2)\n",
    "    weights2 = prop_weights2.reshape((len(prop_weights2), 1))\n",
    "    weighted_covariates2 = np.multiply(covariates2, weights2)\n",
    "    covariate_means2 = np.array(weighted_covariates2.mean(axis=0))\n",
    "    \n",
    "    PSB2 = np.divide(np.abs(covariate_means2 - population_covariate_means), population_covariate_stds)\n",
    "    bad_covariates2 = []\n",
    "    for i in range(len(PSB2)):\n",
    "        if PSB2[i] > 0.2:\n",
    "            bad_covariates2.append((i, PSB2[i]))\n",
    "    \n",
    "    print(\"Covariates for Group 2 with Standad Bias > 0.2: {}\".format(bad_covariates2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ate_for_all_treatment_pairs(treatments):\n",
    "    # compute unweighted mean and standard deviation of each covariate for the pooled sample across all treatments\n",
    "    population_covariate_means = np.array(X.mean(axis=0))\n",
    "    population_covariate_stds = np.array(X.std(axis=0))\n",
    "    \n",
    "    all_means = {}\n",
    "    \n",
    "    for t in treatments:\n",
    "        # compute the weighted mean outcome for this treated subpopulation\n",
    "        T = df_to_T(df, t)\n",
    "        clf = GradBoost(n_estimators=500).fit(X, T)\n",
    "        \n",
    "        treated = (T == 1)\n",
    "        X_treated = X[treated]\n",
    "        prop_weights = (len(X_treated) / len(X)) * np.reciprocal(clf.predict_proba(X_treated)[:,1])\n",
    "        reciprocal = len(X_treated) # np.sum(prop_weights)\n",
    "        weighted_mean = sum(np.multiply(Y[treated], prop_weights)) / reciprocal\n",
    "\n",
    "        print('weighted mean for treatment {}: {}'.format(t, weighted_mean))\n",
    "        all_means[t] = weighted_mean\n",
    "    \n",
    "        # compare the population that got this treatment after weighting to the unweighted full population\n",
    "        covariates = np.array(X_treated)\n",
    "        weights = prop_weights.reshape((len(prop_weights), 1))\n",
    "        weighted_covariates = np.multiply(covariates, weights)\n",
    "        covariate_means = np.array(weighted_covariates.mean(axis=0))\n",
    "\n",
    "        PSB = np.divide(np.abs(covariate_means - population_covariate_means), population_covariate_stds)\n",
    "        bad_covariates = []\n",
    "        for i in range(len(PSB)):\n",
    "            if PSB[i] > 0.2:\n",
    "                bad_covariates.append((i, PSB[i]))\n",
    "\n",
    "        print(\"Covariates for {} with Standad Bias > 0.2: {}\".format(t, bad_covariates))\n",
    "    \n",
    "    # compute all pairwise ate's\n",
    "    for i in range(len(treatments)):\n",
    "        for j in range(i + 1, len(treatments)):\n",
    "            t1 = treatments[i]\n",
    "            t2 = treatments[j]\n",
    "            print('ATE {} - {}: {}'.format(t1, t2, all_means[t1] - all_means[t2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted mean for treatment 1: 1.882741468900802\n",
      "weighted mean for treatment 2: 1.2359359246622876\n",
      "ATE: 0.6468055442385143\n",
      "Covariates for Group 1 with Standad Bias > 0.2: []\n",
      "Covariates for Group 2 with Standad Bias > 0.2: [(119, 0.3716897646245216), (120, 0.2569842745485764)]\n"
     ]
    }
   ],
   "source": [
    "# for our first ate, let's compute the average treatment effect of white vs black\n",
    "t1 = 'WHITE'\n",
    "t2 = 'BLACK'\n",
    "\n",
    "compute_ate_for_treatment_pairs(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted mean for treatment WHITE: 1.882741468900802\n",
      "Covariates for WHITE with Standad Bias > 0.2: []\n",
      "weighted mean for treatment BLACK: 1.2245252087272338\n",
      "Covariates for BLACK with Standad Bias > 0.2: [(119, 0.3803623025755178), (120, 0.26393998484133774)]\n",
      "weighted mean for treatment HISPANIC: 0.9775012519644581\n",
      "Covariates for HISPANIC with Standad Bias > 0.2: [(1, 0.3519019067740821), (119, 0.5408790938493004), (120, 0.39187445702862267)]\n",
      "weighted mean for treatment ASIAN: 0.9314788026914298\n",
      "Covariates for ASIAN with Standad Bias > 0.2: [(1, 0.25976600921747234), (119, 0.611231660362579), (120, 0.3367548537278799)]\n",
      "ATE WHITE - WHITE: 0.0\n",
      "ATE WHITE - BLACK: 0.6582162601735682\n",
      "ATE WHITE - HISPANIC: 0.9052402169363438\n",
      "ATE WHITE - ASIAN: 0.9512626662093722\n",
      "ATE BLACK - BLACK: 0.0\n",
      "ATE BLACK - HISPANIC: 0.24702395676277566\n",
      "ATE BLACK - ASIAN: 0.293046406035804\n",
      "ATE HISPANIC - HISPANIC: 0.0\n",
      "ATE HISPANIC - ASIAN: 0.04602244927302834\n",
      "ATE ASIAN - ASIAN: 0.0\n"
     ]
    }
   ],
   "source": [
    "compute_ate_for_all_treatment_pairs(['WHITE', 'BLACK', 'HISPANIC', 'ASIAN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
