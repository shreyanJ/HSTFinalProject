{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/admissions_processed_morphine_sulfate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X(df):\n",
    "    \n",
    "    # include age and hospital expire flag\n",
    "    covariates = ['age', 'HOSPITAL_EXPIRE_FLAG']\n",
    "    X = df[covariates]\n",
    "    \n",
    "    # include onehots for diagnosis\n",
    "    diagnosis = pd.get_dummies(df.DIAGNOSIS)\n",
    "    diagnosis.columns = ['DIAGNOSIS:%s' %d for d in diagnosis.columns]\n",
    "    X = pd.concat([X, diagnosis], axis=1)\n",
    "    \n",
    "    # include duration of hosptial stay\n",
    "    hosp_duration = (df['DISCHTIME'].astype('datetime64[ns]') - df['ADMITTIME'].astype('datetime64[ns]')).dt.days\n",
    "    X['hosp_duration'] = hosp_duration\n",
    "    \n",
    "    # include onehots for insurance\n",
    "    insur = pd.get_dummies(df.INSURANCE)\n",
    "    insur.columns = ['INSURANCE:%s' %i for i in insur.columns]\n",
    "    X = pd.concat([X, insur], axis=1)  \n",
    "\n",
    "    \n",
    "    # normalize duration because it is non-categorical\n",
    "    d_mu = X['hosp_duration'].mean()\n",
    "    d_std = X['hosp_duration'].std()\n",
    "    X['hosp_duration'] = X['hosp_duration'].apply(lambda dp: (dp-d_mu)/d_std)\n",
    "\n",
    "    # normalize age because non-categorical\n",
    "    age_mu = X['age'].mean()\n",
    "    age_std = X['age'].std()\n",
    "    X['age'] = X['age'].apply(lambda age: (age-age_mu)/age_std)\n",
    "\n",
    "    return X\n",
    "\n",
    "def df_to_T(df, eth):\n",
    "    return df['ETHNICITY'].apply(lambda x: int(x==eth))\n",
    "\n",
    "def df_to_Y(df):\n",
    "    return df['TOTAL_FORM_VAL_DISP_MAX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (6618, 122)\n",
      "T:  (6618,)\n",
      "Y:  (6618,)\n"
     ]
    }
   ],
   "source": [
    "X = df_to_X(df)\n",
    "T = df_to_T(df, 'WHITE')\n",
    "Y = df_to_Y(df)\n",
    "print('X: ', X.shape)\n",
    "print(\"T: \", T.shape)\n",
    "print(\"Y: \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treated ATE with inverse propensity:  1.9243670273957083\n",
      "no treated ATE with inverse propensity:  1.7621489194068773\n",
      "difference between treated and no treated:  0.16221810798883096\n"
     ]
    }
   ],
   "source": [
    "T = df_to_T(df, 'WHITE')\n",
    "\n",
    "clf = LogisticRegression().fit(X, T)\n",
    "\n",
    "treated = np.where(T==1)[0]\n",
    "no_treated = np.where(T==0)[0]\n",
    "\n",
    "predict = list(range(len(X)))\n",
    "for i in range(len(X)):\n",
    "    predict[i] = clf.predict_proba([X.iloc[i]])\n",
    "    \n",
    "ATE = 0\n",
    "for i in treated:\n",
    "    ATE += Y[i]/predict[i][0][1]\n",
    "ans = ATE/len(df)\n",
    "print(\"treated ATE with inverse propensity: \", ans)\n",
    "\n",
    "ATE2 = 0\n",
    "for i in no_treated:\n",
    "    ATE2 += Y[i]/predict[i][0][0]\n",
    "ans2 = ATE2/len(df)\n",
    "print(\"no treated ATE with inverse propensity: \", ans2)\n",
    "\n",
    "print(\"difference between treated and no treated: \", ans - ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treated ATE with inverse propensity:  1.7163226794520907\n",
      "no treated ATE with inverse propensity:  1.9228039884806178\n",
      "difference between treated and no treated:  -0.20648130902852713\n"
     ]
    }
   ],
   "source": [
    "T = df_to_T(df, 'BLACK')\n",
    "\n",
    "clf = LogisticRegression().fit(X, T)\n",
    "\n",
    "treated = np.where(T==1)[0]\n",
    "no_treated = np.where(T==0)[0]\n",
    "\n",
    "predict = list(range(len(X)))\n",
    "for i in range(len(X)):\n",
    "    predict[i] = clf.predict_proba([X.iloc[i]])\n",
    "    \n",
    "ATE = 0\n",
    "for i in treated:\n",
    "    ATE += Y[i]/predict[i][0][1]\n",
    "ans = ATE/len(df)\n",
    "print(\"treated ATE with inverse propensity: \", ans)\n",
    "\n",
    "ATE2 = 0\n",
    "for i in no_treated:\n",
    "    ATE2 += Y[i]/predict[i][0][0]\n",
    "ans2 = ATE2/len(df)\n",
    "print(\"no treated ATE with inverse propensity: \", ans2)\n",
    "\n",
    "print(\"difference between treated and no treated: \", ans - ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treated ATE with inverse propensity:  1.7837247968392604\n",
      "no treated ATE with inverse propensity:  1.9154913152470474\n",
      "difference between treated and no treated:  -0.13176651840778697\n"
     ]
    }
   ],
   "source": [
    "T = df_to_T(df, 'ASIAN')\n",
    "\n",
    "clf = LogisticRegression().fit(X, T)\n",
    "\n",
    "treated = np.where(T==1)[0]\n",
    "no_treated = np.where(T==0)[0]\n",
    "\n",
    "predict = list(range(len(X)))\n",
    "for i in range(len(X)):\n",
    "    predict[i] = clf.predict_proba([X.iloc[i]])\n",
    "    \n",
    "ATE = 0\n",
    "for i in treated:\n",
    "    ATE += Y[i]/predict[i][0][1]\n",
    "ans = ATE/len(df)\n",
    "print(\"treated ATE with inverse propensity: \", ans)\n",
    "\n",
    "ATE2 = 0\n",
    "for i in no_treated:\n",
    "    ATE2 += Y[i]/predict[i][0][0]\n",
    "ans2 = ATE2/len(df)\n",
    "print(\"no treated ATE with inverse propensity: \", ans2)\n",
    "\n",
    "print(\"difference between treated and no treated: \", ans - ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treated ATE with inverse propensity:  1.5354823597319571\n",
      "no treated ATE with inverse propensity:  1.9241439205935043\n",
      "difference between treated and no treated:  -0.38866156086154713\n"
     ]
    }
   ],
   "source": [
    "T = df_to_T(df, 'HISPANIC')\n",
    "\n",
    "clf = LogisticRegression().fit(X, T)\n",
    "\n",
    "treated = np.where(T==1)[0]\n",
    "no_treated = np.where(T==0)[0]\n",
    "\n",
    "predict = list(range(len(X)))\n",
    "for i in range(len(X)):\n",
    "    predict[i] = clf.predict_proba([X.iloc[i]])\n",
    "    \n",
    "ATE = 0\n",
    "for i in treated:\n",
    "    ATE += Y[i]/predict[i][0][1]\n",
    "ans = ATE/len(df)\n",
    "print(\"treated ATE with inverse propensity: \", ans)\n",
    "\n",
    "ATE2 = 0\n",
    "for i in no_treated:\n",
    "    ATE2 += Y[i]/predict[i][0][0]\n",
    "ans2 = ATE2/len(df)\n",
    "print(\"no treated ATE with inverse propensity: \", ans2)\n",
    "\n",
    "print(\"difference between treated and no treated: \", ans - ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
